CS122 Assignment 4 - Join Optimization - Design Document
========================================================

Fill in answers for all questions based on your team's work on Assignment 4.

A:  Refactoring Your Planner
----------------------------

A1.  What did you name your planner base-class?  Briefly describe what
     functionality you migrated into this class.
LH:  AbstractPlannerImpl;
     The base-class is an abstract class, which retrieves the same functionality
     that CostBasedJoinPlanner and SimplePlanner share. Such as, same class
     members and the setter, group-by/aggregation, makeSimpleSelect.

A2.  Was there any functionality that is common to both your SimplePlanner
     and your CostBasedJoinPlanner that you left duplicated in the
     subclasses?  If so, explain your rationale for each part of the
     duplicated functionality.
LH:  Yes. Most of them are in makePlan: when finishing process on FROM & WHERE,
     the planner need to handle with group/aggregation, order by, projection and
     limit/offset. The handling code is exactly the same, but it's a small
     duplication and leaving them there makes code more clear.


B:  Generating Optimal Joins
----------------------------

B1.  Briefly describe how you generate an "optimal" access to a base table.
LH:  Just open the table, create a FileScanNode to walk through the table.
     No optimization here, it's a base case.

B2.  Briefly describe how you decide when it is acceptable to push
     conjuncts down through an outer join.
LH:  As soon as possible according the heuristic.

B3.  The planner in this assignment is still somewhat limited; for example,
     we can't push conjuncts down into subqueries.  Using the stores schema,
     write an example SQL query that includes a subquery, where it would be
     beneficial to push a conjunct down into the subquery.  (Your planner
     obviously doesn't need to perform this optimization.)
LH:  For sure, it cannot push predicate down.
# EXPLAEXPLAIN SELECT * FROM (SELECT store_id FROM stores) AS a WHERE store_id > 1500;
Explain Plan:
    SimpleFilter[pred:  a.store_id > 1500] cost=[tuples=500.3, tupSize=4.3, cpuCost=6000.0, blockIOs=4, largeSeeks=4]
        Rename[resultTableName=a] cost=[tuples=2000.0, tupSize=4.3, cpuCost=4000.0, blockIOs=4, largeSeeks=4]
            Project[values:  [stores.store_id]] cost=[tuples=2000.0, tupSize=4.3, cpuCost=4000.0, blockIOs=4, largeSeeks=4]
                FileScan[table:  stores] cost=[tuples=2000.0, tupSize=13.0, cpuCost=2000.0, blockIOs=4, largeSeeks=4]

B4.  Enumerate the situations where you call prepare() on plans being
     generated.  Since this operation is somewhat expensive, do you
     see any ways to reduce the number of times you call prepare() in
     your implementation?
LH:  * makePlan: 1 for physical plan executing
     * makeLeafPlan: 1st for preparing schema;
                     2nd for updating statistics if node changes after 1st
     * generateOptimalJoin: 1 for updating newNode statistics

B5.  Given a schema t1(a, c1), t2(a, c2), t3(a, c3), and this SQL query:
     SELECT * FROM t1 JOIN t2 ON t1.a = t2.a JOIN t3 ON t2.a = t3.a;

     Assume that we are using the simple cost-based join planning strategy
     described in this assignment.  What issue arises when the planner
     considers joining the pair of tables t1 and t3 first?  What can be done
     to resolve this problem?  (Your planner does not have to implement
     this functionality!)
LH:  Cannot apply predicate t1.a = t3.a.
     Merge to generate a huge equation for conjuncts of equations if possible.

B6.  Is it possible to end up with unused conjuncts (from the WHERE and ON
     clauses) after planning joins?  Briefly explain why or why not.
LH:  No. In the end of generateOptimalJoin, it gets a huge join containing all
     leaf nodes so that every conjunct can be applied here. The optimizer needs
     to push predicates down, after all.

C:  Costing SQL Queries
-----------------------

After you have loaded the stores-28K.sql data and have analyzed all of
the tables in that schema, run the following explain operations and paste
the output from your planner (excluding debug output!).

If there is anything unusual or non-obvious about your output, feel free
to write explanatory notes after your output.

C1.  EXPLAIN SELECT * FROM cities WHERE population > 5000000;
Explain Plan:
    FileScan[table:  cities, pred:  cities.population > 5000000] cost=[tuples=99.0, tupSize=23.8, cpuCost=254.0, blockIOs=1, largeSeeks=1]

Estimated 99.000000 tuples with average size 23.787401
Estimated number of block IOs:  1

C2.  EXPLAIN SELECT store_id FROM stores, cities
     WHERE stores.city_id = cities.city_id AND
           cities.population > 1000000;
Explain Plan:
    Project[values:  [stores.store_id]] cost=[tuples=1771.7, tupSize=5.3, cpuCost=454250.7, blockIOs=5, largeSeeks=5]
        NestedLoop[pred:  cities.city_id == stores.city_id] cost=[tuples=1771.7, tupSize=36.8, cpuCost=452479.0, blockIOs=5, largeSeeks=5]
            FileScan[table:  cities, pred:  cities.population > 1000000] cost=[tuples=225.0, tupSize=23.8, cpuCost=254.0, blockIOs=1, largeSeeks=1]
            FileScan[table:  stores] cost=[tuples=2000.0, tupSize=13.0, cpuCost=2000.0, blockIOs=4, largeSeeks=4]

Estimated 1771.653564 tuples with average size 5.255343
Estimated number of block IOs:  5

C3.  EXPLAIN SELECT store_id FROM stores JOIN
                    (SELECT city_id FROM cities
                     WHERE population > 1000000) AS big_cities
                    ON stores.city_id = big_cities.city_id;
Explain Plan:
    Project[values:  [stores.store_id]] cost=[tuples=1771.7, tupSize=4.7, cpuCost=454475.7, blockIOs=5, largeSeeks=5]
        NestedLoop[pred:  big_cities.city_id == stores.city_id] cost=[tuples=1771.7, tupSize=18.9, cpuCost=452704.0, blockIOs=5, largeSeeks=5]
            Rename[resultTableName=big_cities] cost=[tuples=225.0, tupSize=5.9, cpuCost=479.0, blockIOs=1, largeSeeks=1]
                Project[values:  [cities.city_id]] cost=[tuples=225.0, tupSize=5.9, cpuCost=479.0, blockIOs=1, largeSeeks=1]
                    FileScan[table:  cities, pred:  cities.population > 1000000] cost=[tuples=225.0, tupSize=23.8, cpuCost=254.0, blockIOs=1, largeSeeks=1]
            FileScan[table:  stores] cost=[tuples=2000.0, tupSize=13.0, cpuCost=2000.0, blockIOs=4, largeSeeks=4]

Estimated 1771.653564 tuples with average size 4.736712
Estimated number of block IOs:  5

C4.  EXPLAIN SELECT store_id, property_costs
     FROM stores, cities, states
     WHERE stores.city_id = cities.city_id AND
           cities.state_id = states.state_id AND
           state_name = 'Oregon' AND property_costs > 500000;
Explain Plan:
    Project[values:  [stores.store_id, stores.property_costs]] cost=[tuples=19.6, tupSize=11.7, cpuCost=7555.0, blockIOs=6, largeSeeks=6]
        NestedLoop[pred:  cities.city_id == stores.city_id] cost=[tuples=19.6, tupSize=52.5, cpuCost=7535.4, blockIOs=6, largeSeeks=6]
            NestedLoop[pred:  cities.state_id == states.state_id] cost=[tuples=5.0, tupSize=39.5, cpuCost=560.0, blockIOs=2, largeSeeks=2]
                FileScan[table:  states, pred:  states.state_name == 'Oregon'] cost=[tuples=1.0, tupSize=15.7, cpuCost=51.0, blockIOs=1, largeSeeks=1]
                FileScan[table:  cities] cost=[tuples=254.0, tupSize=23.8, cpuCost=254.0, blockIOs=1, largeSeeks=1]
            FileScan[table:  stores, pred:  stores.property_costs > 500000] cost=[tuples=998.0, tupSize=13.0, cpuCost=2000.0, blockIOs=4, largeSeeks=4]

Estimated 19.568628 tuples with average size 11.656460
Estimated number of block IOs:  6

D:  Extra Credit [OPTIONAL]
---------------------------

If you implemented any extra-credit tasks for this assignment, describe
them here.  The description should be like this, with stuff in "<>" replaced.
(The value i starts at 1 and increments...)

D<i>:  <one-line description>

     <brief summary of what you did, including the specific classes that
     we should look at for your implementation>

     <brief summary of test-cases that demonstrate/exercise your extra work>

E:  Feedback [OPTIONAL]
-----------------------

WE NEED YOUR FEEDBACK!  Thoughtful and constructive input will help us to
improve future versions of the course.  These questions are OPTIONAL, and
your answers will not affect your grade in any way (including if you hate
everything about the assignment and databases in general, or Donnie and/or
the TAs in particular).  Feel free to answer as many or as few of them as
you wish.

E1.  What parts of the assignment were most time-consuming?  Why?

E2.  Did you find any parts of the assignment particularly instructive?
     Correspondingly, did any parts feel like unnecessary busy-work?

E3.  Did you particularly enjoy any parts of the assignment?  Were there
     any parts that you particularly disliked?

E4.  Were there any critical details that you wish had been provided with the
     assignment, that we should consider including in subsequent versions of
     the assignment?

E5.  Do you have any other suggestions for how future versions of the
     assignment can be improved?

